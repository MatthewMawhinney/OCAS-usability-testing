# Test Plan // OCAS Application Form

## Objective

Our objective is to identify points of friction and potential barriers to completion in the web form beginning at <https://www.ontariocolleges.ca/en>.

### Scope

We will be collecting data from observing and recording sessions with on-site users. We will be testing the English language version of the form in the latest version of Chrome, on Windows desktop computers, along with a control group using a recent [Android][1] handheld device. We will provide data from a control group using keyboard-only navigation. 

[We may provide an automated accessibility report][2]. 

Some form submission data will, by necessity, need to be fictional, but our hope is to encourage participants to use [as much of their own data as they are comfortable with][3], so as to increase the realism of time-to-completion. 

## Methods

15 participants will be divided into 3 groups - mobile, desktop with keyboard and mouse, and desktop with keyboard only. 

For the two desktop groups, data will be collected via screen capture software and eye-tracking hardware/software. 

For all groups, tasks will be evaluated via a PURE rubric. 

### Metrics

1. Task evaluation via PURE rubric
2. System Usability Scale
3. Eyetracking heatmap
4. Time-to-completion
5. Success rate
6. Error rate

### Scenario

Users will be asked to complete the application form beginning at <https://www.ontariocolleges.ca/en>, applying to three (3) Ontario colleges. They will be provided with any necessary ["dummy" information][4], including credit card information, OEN, and any other personally identifying information they are not comfortable providing. All other information should be their own (but only [within the boundaries of their comfort][3]). 

### Tasks

[TBD][6]

[After completing a task at the mid-point of the form][7], they will be asked to close their browser session for at least 20 seconds. Following this, the test moderator will have them begin again at the start page, and ask them to resume their application.

### Roles

Each group will have five (5) participants and at least three (3) test administrators. Of the administrators, one will be designated as the moderator. The moderator will liase with the participant, be available to guide them, and address any of their questions or technical issues. The remaining two (2) or more administrators will track the participant's progress through the scenario, rating the participant's ease-of-use for each identified task on the PURE ranking scale.

### Participants

Individual participants have yet to be identified as of this writing (28/05/18). [Once they are identified][5], their demographic information will be recorded here.

Participants are post-graduate certificate students. Efforts have been been made to find a diverse group, including participants from various cultural and socio-economic backgrounds, varying levels of English fluency, and people of different genders. 

### Equipment 

In a mobile lab, outfitted with fully enclosed cubicles for users and mirrored displays for observers. Computers are [Windows][8] machines running [Chrome][8] as the browser client.

Screen capture software used is [Morae][8], and eye-tracking hardware/software is [Tobii][8]. 

### Location

The mobile usability lab is located on the Humber College North Campus, except when it mysteriously disappears.

### Schedule

Sessions will occur Wednesdays from 1:30-4:10, and Thursdays from 11:40-2:30, May 30th-June 20th, 2018.

## TODO

<ul>
	<li><small>[1] Is this what we're doing?</small></li>
	<li><small>[2] Will we?</small></li>
	<li><small>[3] Is this weird?</small></li>
	<li><small>[4] Add this as an appendix when available</small></li>
	<li><small>[5] Participants and their information</small></li>
	<li><small>[6] Determine tasks</small></li>
	<li><small>[7] Determine save point</small></li>
	<li><small>[8] Determine version</small></li>
</ul>